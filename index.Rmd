---
title: "Practical Machine Learning Final Project"
author: "Javier A. Rod√≥n"
date: "29.09.2017"
output: 
  html_document: 
    fig_caption: yes
    fig_height: 7
    fig_width: 9
    keep_md: yes
    number_sections: yes
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r ref.label="libraries", echo=FALSE, message=FALSE, results='hide'}
```
```{r ref.label="obtain.data", echo=FALSE, results='hide'}
```
```{r ref.label="data.clean", echo=FALSE, message=FALSE, results='hide'}
```
```{r ref.label="data.split", echo=FALSE, message=FALSE, results='hide'}
```
```{r ref.label="model.train", echo=FALSE, message=FALSE, results='hide'}
```
```{r ref.label="model.results", echo=FALSE, message=FALSE, results='hide'}
```


# Synopsis
The final project of the Practical Machine Learning course involves the construction of a predictive model and its application to a data set to obtain the answers to the final quiz.
The model is constructed based on the Weight Lifting Exercises (WLE) dataset provided by Velloso et al. (2013), which contains information on the execution of a dumbbell exercise performed in different ways.
After exploring the data we selected `r dim(train.Data)[2]-1` predictors to train the model. We trained 4 different classification algorithms, with "Random Forest" yielding the best results. In the end we obtain a model with a `r con.M.RF$overall["Accuracy"]*100`$\,\%$ accuracy on the test dataset, which predicted $100\,\%$ of the quiz results.

# Preparation
## Nature of the data
The data consist on information from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. The goal is to predict the manner in which they did the exercise. This is the "classe" variable in the training set.

## Obtaining the data
The original dataset, as well as information on its contents, can be obtained from http://web.archive.org/web/20161224072740/http:/groupware.les.inf.puc-rio.br/har. It has been processed for this project by the course instructors and the resulting datasets, to be used in this project, are available at https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv and https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv.

We begin by setting up the work enviroment:
```{r libraries, warning=FALSE, message=FALSE, results='hide'}
## Load the required libraries
libraries <- c("caret","corrplot","parallel","doParallel")
lapply(libraries, library, character.only = TRUE)
options(digits = 2)
## Set up working directory
work.dir <- "Course8Week4Project"
if (!dir.exists(paste("..", work.dir, sep = "/"))) dir.create(work.dir)
if (is.null(getwd())) setwd(work.dir)
```

Then we download and load the data:
```{r obtain.data, warning=FALSE, message=FALSE}
## Download the data
file.name <- c("pml-training.csv","pml-testing.csv")
data.url <- c("~/data_science/R_Programming/Course8Week4Project/pml-training.csv",
              "~/data_science/R_Programming/Course8Week4Project/pml-testing.csv")
for (i in 1:2) {
      if (!file.exists(file.name[i])) download.file(data.url[i])
}
## Load the data
train.Data <- read.csv(file.name[1], na.strings = c("","NA","#DIV/0!"))
test.Data <- read.csv(file.name[2], na.strings = c("","NA","#DIV/0!"))
```

The first attempt at loading the data resulted on several columns marked as "factor" or "character" when they should have been "numeric". A quick exploration with `str()` and `summary()` showed that this was due to the occurrence of several "#DIV/0!" entries in the data file. Therefore the loading call with `read.csv()` was modified accordingly as shown before.

## Data exploration
We perform a customary examination of the data:
```{r data.explore, cache=TRUE}
## Data exploration
dim(test.Data); dim(train.Data)
names(train.Data[which(names(test.Data)!=names(train.Data))]); names(test.Data[which(names(test.Data)!=names(train.Data))])  # Differing names
```

We see that there are `r dim(test.Data)[2]` potential predictors.
```{r results='hide'}
str(train.Data) ; str(test.Data)
summary(train.Data) ; summary(test.Data) # Shows many NA
```

The output of the last 4 commands is hidden due to its lenght, but it shows that there are many columns full of NAs.
```{r}
sum(apply(test.Data,2,function(x) mean(is.na(x)) > 0.5)) # Useless variables
```

This shows that there in fact 100 columns with at least half the content being NAs. This is checked on the test dataset since there is no point to use variables in the model that we know do not appear in the test dataset.
We also see from the `str()` call that there are variables that cannot be considered predictors, since they are entirely circumstancial and not affecting the outcome. Those are the following:
```{r}
names(test.Data[,c(1:6)])
```

The next step is to get rid of those useless variables.

## Cleaning the data
We begin by eliminating the columns with more than $50\,\%$ of NAs, then the variables with near-zero variance, and finally the circumstantial variables:
```{r data.clean, cache=TRUE}
## Eliminate columns with too many NAs
NA.Cols <- apply(test.Data,2,function(x) mean(is.na(x))) > 0.5
train.Data <- train.Data[,!NA.Cols]
test.Data <- test.Data[,!NA.Cols]
## Eliminate columns with near-zero variance
NZV.Cols <- nearZeroVar(train.Data, foreach = T)
train.Data <- train.Data[,-NZV.Cols]
test.Data <- test.Data[,-NZV.Cols]
## Eliminate circumstantial variables.
train.Data <- train.Data[,-c(1:6)]
test.Data <- test.Data[,-c(1:6)]
```

After this cleaning, the remaining predictors are `r dim(train.Data)[2]-1`.

# Building the model
## Splitting the data
Once the datasets were cleaned we constructed our training and testing datasets, assigning $75\%$ of the observations to the training dataset and the remaining $25\%$ being left for testing purposes:
```{r data.split, cache=TRUE}
## Split the data
set.seed(1780)
in.Train <- createDataPartition(train.Data$classe, p = 0.75, list = F)
split.Train.Data <- train.Data[in.Train,]
split.Test.Data <- train.Data[-in.Train,]
```

## Predictor selection
To choose which predictors to use to build the model, we first checked the correlation matrix of the predictors:
```{r predictor.explore, cache=TRUE, fig.cap="\\label{fig:corrmatrix} Lower correlation matrix of the predictors in the training dataset. The amount of correlation is shown by the shade of blue, with darker shades representing higher correlation"}
## Explore the variables
## Correlation matrix
cor.M <- cor(split.Train.Data[,-53]) 
corrplot(abs(cor.M),method = "square", 
         order = "hclust", type = "lower", diag = F,
         tl.col = "black", tl.cex = 0.75, tl.srt = 30,
         cl.lim = c(0,1), cl.cex = 0.8, cl.ratio = 0.1)
```

The figure above shows that there are just a few predictors that are highly correlated. They could potentially be combined by performing a Principal Components analysis, however the gain would not be much and therefore it is not performed.

Further exploration by plotting the predictors showed no obvious distinction of the outcome. Therefore, for brevity only one of said plots is shown here.
```{r plot.example, cache=TRUE, fig.cap="\\label{fig:example} Example of the exploratory plots, showing no obvious distinction of the outcome."}
qplot(yaw_forearm, yaw_arm, data = split.Train.Data, color = classe)
```

In conclusion, we decided to proceed with all the available predictors.

## Algorithm training
We chose four different popular classifiction algorithms: Random Forest, Classification Trees, Stochastic Gradient Boosting, and Conditional Inference Trees.

For the training we used a 10-Fold cross-validation resampling of the data, and the computation was parallelized:
```{r model.train, message=FALSE, cache=TRUE}
## Create the models
### Parallelize
cluster <- makeCluster(detectCores() - 1) # Leave 1 core for OS
registerDoParallel(cluster)
### Fit models
CV.control <- trainControl(method = "cv", number = 10, allowParallel = T, verboseIter = T)

model.Fit.RF <- train(classe ~ ., data = split.Train.Data, 
                      method = "rf", trControl = CV.control)
model.Fit.CART <- train(classe ~ ., data = split.Train.Data, 
                        method = "rpart", trControl = CV.control)
model.Fit.Boosted <- train(classe ~ ., data = split.Train.Data, 
                           method = "gbm", trControl = CV.control)
model.Fit.CondTree <- train(classe ~ ., data = split.Train.Data, 
                            method = "ctree", trControl = CV.control)
### Stop parallelization
stopCluster(cluster)
registerDoSEQ()
```

# Results
We applied the resulting models to the test dataset to obtain the expected accuracies and out-of-sample errors. The confusion matrices show the expected performance of the different algorithms.
```{r model.results, cache=TRUE}
### Model results
pred.RF <- predict(model.Fit.RF,split.Test.Data)
con.M.RF <- confusionMatrix(split.Test.Data$classe,pred.RF)
model.Fit.RF ; con.M.RF$table ; con.M.RF$overall["Accuracy"]

pred.CART <- predict(model.Fit.CART,split.Test.Data)
con.M.CART <- confusionMatrix(split.Test.Data$classe,pred.CART)
model.Fit.CART ; con.M.CART$table ; con.M.CART$overall["Accuracy"]

pred.Boosted <- predict(model.Fit.Boosted,split.Test.Data)
con.M.Boosted <- confusionMatrix(split.Test.Data$classe,pred.Boosted)
model.Fit.Boosted ; con.M.Boosted$table ; con.M.Boosted$overall["Accuracy"]

pred.CondTree <- predict(model.Fit.CondTree,split.Test.Data)
con.M.CondTree <- confusionMatrix(split.Test.Data$classe,pred.CondTree)
model.Fit.CondTree ; con.M.CondTree$table ; con.M.CondTree$overall["Accuracy"]
```

We see that the Random Forest algorithm is the one that performs the best, with an accuracy of `r con.M.RF$overall["Accuracy"]*100`$\,\%$ or an *out-of-sample error* of `r (1-con.M.RF$overall["Accuracy"])*100`$\,\%$. The Classification Trees was the worst, being no better than a coin flip.

# Conclusion
We applied the Random Forest model to the dataset containing the data for the quiz results. The answer we obtained were all correct, scoring $100\,\%$ in the quiz.
```{r quiz.results}
## Obtain quiz results
quiz.Res <- predict(model.Fit.RF,test.Data)
quiz.Res
```


